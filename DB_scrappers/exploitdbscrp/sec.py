from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import time

# Path to Chrome binary and driver
CHROME_BIN = "/usr/bin/chromium-browser"
CHROMEDRIVER_PATH = "/usr/bin/chromedriver"  # You need to install this

# Setup Chrome options
options = Options()
options.add_argument("--headless")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.binary_location = CHROME_BIN

# Setup service
service = Service(CHROMEDRIVER_PATH)
driver = webdriver.Chrome(service=service, options=options)

with open("ghdb_dorks_only.txt", "w", encoding="utf-8") as file:
    for page in range(1, 531):
        print(f"[+] Scraping page {page}")
        driver.get(f"https://www.exploit-db.com/google-hacking-database?page={page}")
        time.sleep(2)

        soup = BeautifulSoup(driver.page_source, "html.parser")
        rows = soup.select("table tbody tr")

        for row in rows:
            cols = row.find_all("td")
            if len(cols) >= 2:
                a_tag = cols[1].find("a")
                if a_tag:
                    dork = a_tag.text.strip()
                    if dork.lower() not in [
                        "submit entry", "search exploit-db", "searchsploit manual",
                        "exploit statistics", "proving grounds"
                    ]:
                        file.write(dork + "\n")

driver.quit()
print("âœ… Scraping complete. Dorks saved.")
