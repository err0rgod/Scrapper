from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import time

# Set up headless Chrome
options = Options()
options.add_argument("--headless")
options.add_argument("--disable-gpu")
driver = webdriver.Chrome(options=options)

with open("ghdb_dorks_only.txt", "w", encoding="utf-8") as file:
    for page in range(1, 531):
        print(f"Scraping page {page}...")
        url = f"https://www.exploit-db.com/google-hacking-database?page={page}"
        driver.get(url)
        time.sleep(3)  # Wait for JS to render

        soup = BeautifulSoup(driver.page_source, "html.parser")
        rows = soup.select("table.exploits-table tbody tr")

        for row in rows:
            cols = row.find_all("td")
            if len(cols) >= 2:
                a_tag = cols[1].find("a")
                if a_tag:
                    dork = a_tag.text.strip()
                    file.write(dork + "\n")

driver.quit()
