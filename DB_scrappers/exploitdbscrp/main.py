from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import time

# Setup headless Chrome
options = Options()
options.add_argument("--headless")
options.add_argument("--disable-gpu")
driver = webdriver.Chrome(options=options)

with open("ghdb_dorks_only.txt", "w", encoding="utf-8") as file:
    for page in range(1, 20):  # Change to 531 for full scrape
        url = f"https://www.exploit-db.com/google-hacking-database?page={page}"
        print(f"Scraping page {page}...")
        driver.get(url)
        time.sleep(2)

        soup = BeautifulSoup(driver.page_source, "html.parser")
        table_rows = soup.select("table tbody tr")
        
        for row in table_rows:
            columns = row.find_all("td")
            if len(columns) >= 2:
                dork_link = columns[1].find("a")
                if dork_link:
                    dork = dork_link.text.strip()
                    file.write(dork + "\n")

driver.quit()
